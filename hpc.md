RCS High Performance Computing (HPC) Documentation
==================================================

* Logging In
* Available Filesystems
* Using the Batch System
* Third-Party Software
* Compiling from Source Code
* System Architecture
* Community Condo Model
* Policies

In 2016, the Geophysical Institute launched Chinook as an energy efficient
linux cluster purchased from [Penguin Computing,
Inc](http://www.penguincomputing.com/). Chinook is named in  honor of long time
GI colleague Kevin Engle's unique, strong, collaborative  nature and passion for
salmon and Alaska. In 2016 and 2017, Chinook expansions  were supported with
funding from the M. J. Murdock Charitable Trust. Chinook  is also made possible
by the Geophysical Institute, IARC, the Institute of  Arctic Biology, the Vice
Chancellor of Research, and your fellow colleagues  who contribute shares.

== Chinook

Chinook is the foundation for a new energy-efficient, condo-style HPC cluster
for UA researchers. The computing environment hosted on Chinook includes:

* 100+ Relion 1900 Compute Nodes each with dual Intel Xeon 12- or 14-core
  processors (24 or 28 cores per node) and 128 GB memory
* 3x Relion 1900 Compute Nodes each with dual Intel Xeon 14-core processors
  (28 cores per node) and 1.5 TB memory
* 2x Relion 1903GT Compute Nodes each with dual Intel Xeon 14-core processors
  (28 cores per node), 128 GB memory, and 3 dual GPU Tesla K80m accelerators
* Multiple login nodes with dual Intel Xeon processors and 48 or more GBs
  memory
* CentOS operating system, Slurm open-source workload management software,
  and Scyld ClusterWare HPC management software
* Compute and login node access to the 307 TB Lustre scratch file system

Are you interested in using the Chinook HPC cluster in your computational
work? Please read our directions on how to [obtain RCS project and user
accounts](https://www.gi.alaska.edu/research-computing-systems/getting-access).

== XSEDE/Campus Champions

Members of RCS staff are part of [XSEDE's Campus Champions
program](https://www.xsede.org/community-engagement/campus-champions),
providing support and contacts for XSEDE systems and XSEDE startup allocations.
Please contact RCS if you are interested in pursuing XSEDE resources.
